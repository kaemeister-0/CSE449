{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7AILQPerD6-",
        "outputId": "928c1823-a030-49a8-b96a-65dbf7f09644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=a299db90907fdd6d01606117d672f52c63d02448d9dc447cd98d8bd4c187bb5b\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import multiprocessing\n",
        "import psutil  # For system monitoring"
      ],
      "metadata": {
        "id": "3F_nDOhZq5jW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Simulate large-scale dataset\n",
        "data_size = 1000000\n",
        "data = np.random.random(data_size)\n",
        "\n",
        "# Function to simulate processing task\n",
        "def process_data(data_chunk):\n",
        "    # Perform some computation on the data\n",
        "    result = np.mean(data_chunk)\n",
        "    return result\n",
        "\n",
        "# Function to dynamically allocate resources based on system metrics\n",
        "def dynamic_resource_allocation():\n",
        "    try:\n",
        "      while True:\n",
        "          # Get current system metrics\n",
        "          cpu_percent = psutil.cpu_percent()  # CPU utilization percentage\n",
        "          available_memory = psutil.virtual_memory().available  # Available memory in bytes\n",
        "\n",
        "          # Define resource allocation based on system metrics\n",
        "          if cpu_percent < 80 and available_memory > 2 * data_size * 8:  # Example thresholds\n",
        "              num_processes = multiprocessing.cpu_count()  # Use all available cores\n",
        "          else:\n",
        "              num_processes = multiprocessing.cpu_count() // 2  # Use half of the available cores\n",
        "\n",
        "          # Split data into chunks for parallel processing\n",
        "          data_chunks = np.array_split(data, num_processes)\n",
        "\n",
        "          # Process data chunks in parallel\n",
        "          start_time = time.time()\n",
        "          with multiprocessing.Pool(num_processes) as pool:\n",
        "              results = pool.map(process_data, data_chunks)\n",
        "          parallel_time = time.time() - start_time\n",
        "\n",
        "          print(f\"Parallel processing with {num_processes} processes took {parallel_time} seconds\")\n",
        "\n",
        "          # Sleep for a while before checking system metrics again\n",
        "          time.sleep(10)  # Adjust as needed\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"Program interrupted. Exiting gracefully...\")\n",
        "        # Additional cleanup if needed\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    dynamic_resource_allocation()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTOU9-4Up46v",
        "outputId": "eff0d13d-a0e6-4c4e-83cd-e911e06868d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parallel processing with 2 processes took 0.09510135650634766 seconds\n",
            "Program interrupted. Exiting gracefully...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from pyspark import SparkContext\n",
        "\n",
        "# Initialize Spark context\n",
        "sc = SparkContext(\"local\", \"ParallelAlgorithms\")\n",
        "\n",
        "# Define process_data function (for demonstration purposes)\n",
        "def process_data(data):\n",
        "    return data * 2\n",
        "\n",
        "# Define your data (or pass it as a parameter to the functions)\n",
        "data = sc.parallelize(range(1000000))  # Example data\n",
        "\n",
        "# 1. MapReduce\n",
        "def map_reduce_example(data):\n",
        "    # Map phase: Process each element in parallel\n",
        "    mapped_data = data.map(process_data)\n",
        "\n",
        "    # Reduce phase: Aggregate results\n",
        "    reduced_result = mapped_data.reduce(lambda x, y: x + y)\n",
        "\n",
        "    return reduced_result\n",
        "\n",
        "# 2. Parallel Sorting\n",
        "def parallel_sorting_example(data):\n",
        "    sorted_data = data.sortBy(lambda x: x)\n",
        "    return sorted_data.collect()\n",
        "\n",
        "# 3. Parallel Search\n",
        "def parallel_search_example(data, target):\n",
        "    # Perform parallel search\n",
        "    result = data.filter(lambda x: x == target).collect()\n",
        "    return result\n",
        "\n",
        "# 4. Parallel Join\n",
        "def parallel_join_example(data1, data2):\n",
        "    # Example datasets\n",
        "    data1 = sc.parallelize([(1, 'A'), (2, 'B'), (3, 'C')])\n",
        "    data2 = sc.parallelize([(1, 'X'), (2, 'Y'), (4, 'Z')])\n",
        "\n",
        "    # Perform parallel join\n",
        "    joined_data = data1.join(data2)\n",
        "    return joined_data.collect()\n",
        "\n",
        "# 5. Parallel Aggregation\n",
        "def parallel_aggregation_example(data):\n",
        "    aggregated_result = data.reduce(lambda x, y: x + y)\n",
        "    return aggregated_result\n",
        "\n",
        "# 6. Parallel Graph Algorithms (e.g., Parallel BFS)\n",
        "def parallel_bfs_example(graph, start_node):\n",
        "    # Perform parallel BFS\n",
        "    visited = []\n",
        "    queue = [start_node]\n",
        "\n",
        "    while queue:\n",
        "        node = queue.pop(0)\n",
        "        if node not in visited:\n",
        "            visited.append(node)\n",
        "            neighbors = graph[node]\n",
        "            queue.extend(neighbors)\n",
        "\n",
        "    return visited\n",
        "\n",
        "# 7. Parallel Machine Learning Algorithms (e.g., Parallel k-means)\n",
        "def parallel_kmeans_example(data, k):\n",
        "    # Perform parallel k-means clustering\n",
        "    # (Note: This is a simplified example)\n",
        "    centroids = data.takeSample(False, k)\n",
        "    # Iterate until convergence\n",
        "    # Implement k-means clustering algorithm here\n",
        "    return centroids\n",
        "\n",
        "# Example usage\n",
        "print(\"MapReduce Example:\", map_reduce_example(data))\n",
        "print(\"Parallel Sorting Example:\", parallel_sorting_example(data))\n",
        "print(\"Parallel Search Example:\", parallel_search_example(data, 42))\n",
        "print(\"Parallel Join Example:\", parallel_join_example(data, data))\n",
        "print(\"Parallel Aggregation Example:\", parallel_aggregation_example(data))\n",
        "print(\"Parallel BFS Example:\", parallel_bfs_example({1: [2, 3], 2: [4, 5], 3: [], 4: [], 5: []}, 1))\n",
        "print(\"Parallel k-means Example:\", parallel_kmeans_example(data, 3))\n",
        "\n",
        "# Stop Spark context\n",
        "sc.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZynVYqjsxdO",
        "outputId": "9d2931a5-1bfd-4f03-e19c-d5578d7deb15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MapReduce Example: 999999000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parallel Search Example: [42]\n",
            "Parallel Join Example: [(2, ('B', 'Y')), (1, ('A', 'X'))]\n",
            "Parallel Aggregation Example: 499999500000\n",
            "Parallel BFS Example: [1, 2, 3, 4, 5]\n",
            "Parallel k-means Example: [179643, 200926, 302507]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "import time\n",
        "\n",
        "# Example data for demonstration\n",
        "data = list(range(10))\n",
        "\n",
        "# 1. Parallel Map\n",
        "def parallel_map(function, data):\n",
        "    with multiprocessing.Pool() as pool:\n",
        "        results = pool.map(function, data)\n",
        "    return results\n",
        "\n",
        "# 2. Parallel Reduce\n",
        "def parallel_reduce(function, data):\n",
        "    with multiprocessing.Pool() as pool:\n",
        "        results = pool.map(function, data)\n",
        "    return sum(results)\n",
        "\n",
        "# 3. Parallel Task Queue\n",
        "def worker(task_queue, result_queue):\n",
        "    while True:\n",
        "        task = task_queue.get()\n",
        "        if task is None:\n",
        "            break\n",
        "        result = process_task(task)\n",
        "        result_queue.put(result)\n",
        "\n",
        "def parallel_task_queue(tasks):\n",
        "    task_queue = multiprocessing.Queue()\n",
        "    result_queue = multiprocessing.Queue()\n",
        "\n",
        "    # Start worker processes\n",
        "    num_processes = multiprocessing.cpu_count()\n",
        "    processes = [multiprocessing.Process(target=worker, args=(task_queue, result_queue)) for _ in range(num_processes)]\n",
        "    for process in processes:\n",
        "        process.start()\n",
        "\n",
        "    # Distribute tasks to worker processes\n",
        "    for task in tasks:\n",
        "        task_queue.put(task)\n",
        "\n",
        "    # Stop worker processes\n",
        "    for _ in range(num_processes):\n",
        "        task_queue.put(None)\n",
        "    for process in processes:\n",
        "        process.join()\n",
        "\n",
        "    # Retrieve results from result queue\n",
        "    results = []\n",
        "    while not result_queue.empty():\n",
        "        result = result_queue.get()\n",
        "        results.append(result)\n",
        "\n",
        "    return results\n",
        "\n",
        "# Example function for processing data\n",
        "def process_data(data):\n",
        "    # Simulate some processing time\n",
        "    time.sleep(1)\n",
        "    return data * 2\n",
        "\n",
        "# Example function for reducing data\n",
        "def reduce_data(data):\n",
        "    return sum(data)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Example usage\n",
        "    print(\"Parallel Map Example:\", parallel_map(process_data, data))\n",
        "    print(\"Parallel Reduce Example:\", parallel_reduce(process_data, data))\n",
        "    print(\"Parallel Task Queue Example:\", parallel_task_queue(data))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uz-AuTSDtfD9",
        "outputId": "fdde7f60-5f95-407a-c77c-93af98128cde"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parallel Map Example: [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n",
            "Parallel Reduce Example: 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Process Process-25:\n",
            "Process Process-26:\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"<ipython-input-9-dab7ecb335f5>\", line 25, in worker\n",
            "    result = process_task(task)\n",
            "NameError: name 'process_task' is not defined\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-dab7ecb335f5>\", line 25, in worker\n",
            "    result = process_task(task)\n",
            "NameError: name 'process_task' is not defined\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parallel Task Queue Example: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MPI\n"
      ],
      "metadata": {
        "id": "MYS5uJo7t-FW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mpi4py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZr0ow-RuAhG",
        "outputId": "bb08af14-2a36-49b4-da9d-fa9b272cbdd2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mpi4py\n",
            "  Downloading mpi4py-3.1.6.tar.gz (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mpi4py\n",
            "  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-3.1.6-cp310-cp310-linux_x86_64.whl size=2746313 sha256=6a8f11a6e8e1aec39cec9fb83f1ba62be8dde7cf8fe76b08e61a0950482f6d05\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/ca/89/8fc1fb1c620afca13bb41c630b1f948bbf446e0aaa4b762e10\n",
            "Successfully built mpi4py\n",
            "Installing collected packages: mpi4py\n",
            "Successfully installed mpi4py-3.1.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mpi4py import MPI\n",
        "\n",
        "def distribute_data(data, size):\n",
        "\n",
        "    data_size = 1000000\n",
        "    data = np.random.random(data_size)\n",
        "    data_chunks = []\n",
        "    chunk_size = len(data) // size\n",
        "    remainder = len(data) % size\n",
        "    start_idx = 0\n",
        "\n",
        "    for i in range(size):\n",
        "        end_idx = start_idx + chunk_size + (1 if i < remainder else 0)\n",
        "        data_chunks.append(data[start_idx:end_idx])\n",
        "        start_idx = end_idx\n",
        "\n",
        "    return data_chunks\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    comm = MPI.COMM_WORLD\n",
        "    rank = comm.Get_rank()\n",
        "    size = comm.Get_size()\n",
        "\n",
        "# Master-Slave Architecture\n",
        "    if rank == 0:  # Master process\n",
        "        # Allocate memory for data and results arrays\n",
        "        cluster_array = ...\n",
        "        assignment_results = ...\n",
        "\n",
        "        # Read data from disk or memory\n",
        "        data = ...\n",
        "\n",
        "        size_buffer = bytearray(4)  # Assuming an integer requires 4 bytes\n",
        "        size_buffer[:4] = size.to_bytes(4, byteorder='big')  # Convert integer to bytes and store in buffer\n",
        "\n",
        "        # Broadcast size to all processes\n",
        "        comm.Bcast(size_buffer, root=0)\n",
        "\n",
        "        # Distribute data across processors\n",
        "        data_chunks = distribute_data(data, size)\n",
        "        for i in range(1, size):\n",
        "            comm.Send(data_chunks[i], dest=i)\n",
        "\n",
        "        # Receive results from slaves\n",
        "        for i in range(1, size):\n",
        "            assignment_results[i] = comm.Recv(source=i)\n",
        "\n",
        "        # Analyze results and perform further computations\n",
        "\n",
        "    else:  # Slave processes\n",
        "        # Receive processor number from master\n",
        "        processor_number = comm.Bcast(None, root=0)\n",
        "\n",
        "        # Receive data chunk from master\n",
        "        data_chunk = comm.Recv(source=0)\n",
        "\n",
        "        # Perform k-means assignment for assigned data chunk\n",
        "        local_assignments = kmeans_assignment(data_chunk)\n",
        "\n",
        "        # Send results back to master\n",
        "        comm.Send(local_assignments, dest=0)"
      ],
      "metadata": {
        "id": "5T5dOoV7t9pe"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}